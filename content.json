{"meta":{"title":"Yi Yang's Blog","subtitle":"try it !","description":null,"author":"Yi Yang","url":"http://yylin1.github.io"},"pages":[{"title":"about me","date":"2018-09-15T07:17:15.000Z","updated":"2018-09-15T07:27:49.800Z","comments":true,"path":"about/index.html","permalink":"http://yylin1.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"我的第一次提交","slug":"我的第一次提交","date":"2018-09-16T06:47:18.000Z","updated":"2018-09-16T15:09:20.432Z","comments":true,"path":"2018/09/16/我的第一次提交/","link":"","permalink":"http://yylin1.github.io/2018/09/16/我的第一次提交/","excerpt":"Kubeflow 課程手把手實作實驗環境 Minikube GPU Cluster Katacoda kubeflow實作目錄 Jupyter Hub 實作 TF-operator PyTorch-operator MPI Training","text":"Kubeflow 課程手把手實作實驗環境 Minikube GPU Cluster Katacoda kubeflow實作目錄 Jupyter Hub 實作 TF-operator PyTorch-operator MPI Training 更多實作｜參考 其他可以透過 katacoda 線上學習 Deploying Github Issue Summarization with Kubeflow Deploying PyTorch with Kubeflow Deploying Kubeflow Deploying Kubeflow with Ksonnet minikube 部署kubeflow確認已經部署完成 minikube1minikube start --memory=8192 --cpus=4 --kubernetes-version=v1.10.6 ksonnet install1curl -L https://github.com/ksonnet/ksonnet/releases/download/v0.11.0/ks_0.11.0_linux_amd64.tar.gz | tar xvz &amp;&amp; mv ks_0.11.0_linux_amd64/ks /usr/local/bin/ks &amp;&amp; rm -rf ks_0.11.0_linux_amd64/ kubeflow install12export KUBEFLOW_VERSION=0.2.2curl https://raw.githubusercontent.com/kubeflow/kubeflow/v0.2.2/scripts/deploy.sh | bash 檢查部署後狀態 （會需要花時間下載Images）1234567891011$ kubectl get podsNAME READY STATUS RESTARTS AGEambassador-59cb5ccd89-cltqx 2/2 Running 0 1mambassador-59cb5ccd89-sl87k 2/2 Running 0 1mambassador-59cb5ccd89-szchn 2/2 Running 0 1mcentraldashboard-7d7744cccb-cntj6 1/1 Running 0 1mspartakus-volunteer-55577f4bd9-kgnvv 1/1 Running 0 1mtf-hub-0 1/1 Running 0 1mtf-job-dashboard-bfc9bc6bc-wmbj5 1/1 Running 0 1mtf-job-operator-v1alpha2-756cf9cb97-r45kk 1/1 Running 0 1m 補充：Minikube for Kubeflow (Bootstrapper)安裝kubeflow 使用 Bootstrapper 1$ curl -O https://raw.githubusercontent.com/kubeflow/kubeflow/v0.2-branch/bootstrap/bootstrapper.yaml 執行config 1$ kubectl create -f bootstrapper.yaml 創建的項目1234namespace \"kubeflow-admin\" createdclusterrolebinding.rbac.authorization.k8s.io \"kubeflow-cluster-admin\" createdpersistentvolumeclaim \"kubeflow-ksonnet-pvc\" createdstatefulset.apps \"kubeflow-bootstrapper\" created 查看是否建立成功123456$ kubectl get nsNAME STATUS AGEdefault Active 1mkube-public Active 1mkube-system Active 1mkubeflow-admin Active 53s 這步驟會需要5~8分鐘時間，需要下載各項Images123456789$ kubectl -n kubeflow get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEambassador ClusterIP 10.97.168.31 &lt;none&gt; 80/TCP 1mambassador-admin ClusterIP 10.99.5.81 &lt;none&gt; 8877/TCP 1mcentraldashboard ClusterIP 10.111.104.142 &lt;none&gt; 80/TCP 1mk8s-dashboard ClusterIP 10.102.65.244 &lt;none&gt; 443/TCP 1mtf-hub-0 ClusterIP None &lt;none&gt; 8000/TCP 1mtf-hub-lb ClusterIP 10.101.15.28 &lt;none&gt; 80/TCP 1mtf-job-dashboard ClusterIP 10.106.133.49 &lt;none&gt; 80/TCP 1m 啟用Jupyter Hub與 kubeflow Dashboard1234$ POD=`kubectl -n kubeflow get pods --selector=service=ambassador | awk '&#123;print $1&#125;' | tail -1`$ kubectl -n kubeflow port-forward $POD 8080:80 2&gt;&amp;1 &gt;/dev/null &amp;$ POD=`kubectl -n kubeflow get pods --selector=app=tf-hub | awk '&#123;print $1&#125;' | tail -1`$ kubectl -n kubeflow port-forward $POD 8000:8000 2&gt;&amp;1 &gt;/dev/null &amp; Kubeflow dashboard at http://localhost:8080/JupyterHub at http://localhost:8000/ Upgrading Kubeflow Deployments 如果CRD API 後續如何更新？ 刪除TFJobs v1alpha1，因為K8無法部署多個版本的CRD1kubectl delete crd tfjobs.kubeflow.org Jupyter Hub 測試 Kubeflow檢查 Kubeflow 元件部署結果12345678910$ kubectl get pods NAME READY STATUS RESTARTS AGEambassador-59cb5ccd89-mxdpz 2/2 Running 0 13mambassador-59cb5ccd89-nzcbt 2/2 Running 0 13mambassador-59cb5ccd89-rzrs5 2/2 Running 0 13mcentraldashboard-7d7744cccb-kh7r6 1/1 Running 0 13mspartakus-volunteer-56d4cf6bbf-vf9nt 1/1 Running 0 13mtf-hub-0 1/1 Running 0 13mtf-job-dashboard-bfc9bc6bc-zfk64 1/1 Running 0 13mtf-job-operator-v1alpha2-756cf9cb97-w2w9q 1/1 Running 0 13m 確認後就可以登入 Jupyter Notebook，但這邊需要修改 Kubernetes Service，透過以下指令進行： 1234567$ kubectl -n default edit svc tf-hub-lb···spec: . . type: NodePort··· 查看minikube ip12$ minikube ip 192.168.99.100 確認Service對應的IP:port12345678910$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEambassador ClusterIP 10.97.154.89 &lt;none&gt; 80/TCP 15mambassador-admin ClusterIP 10.107.124.60 &lt;none&gt; 8877/TCP 15mcentraldashboard ClusterIP 10.107.126.80 &lt;none&gt; 80/TCP 15mk8s-dashboard ClusterIP 10.103.240.15 &lt;none&gt; 443/TCP 15mkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 17mtf-hub-0 ClusterIP None &lt;none&gt; 8000/TCP 15mtf-hub-lb NodePort 10.100.10.226 &lt;none&gt; 80:30552/TCP 15mtf-job-dashboard ClusterIP 10.97.210.229 &lt;none&gt; 80/TCP 15m 連接對應的192.168.99.100:30552即可以開啟Jupyer Hub帳密自行輸入,會自動建立新帳號 登入後點選Start My Server按鈕來建立 Server 的 Spawner options，預設會有多種映像檔可以使用： 選擇資源後就會看到minikube環境pod就會多一個 jupyter-admin container正在建立 1234567891011kubectl get podNAME READY STATUS RESTARTS AGEambassador-59cb5ccd89-mxdpz 2/2 Running 0 21mambassador-59cb5ccd89-nzcbt 2/2 Running 0 21mambassador-59cb5ccd89-rzrs5 2/2 Running 0 21mcentraldashboard-7d7744cccb-kh7r6 1/1 Running 0 21mjupyter-admin 0/1 ContainerCreating 0 3mspartakus-volunteer-56d4cf6bbf-vf9nt 1/1 Running 0 21mtf-hub-0 1/1 Running 0 21mtf-job-dashboard-bfc9bc6bc-zfk64 1/1 Running 0 21mtf-job-operator-v1alpha2-756cf9cb97-w2w9q 1/1 Running 0 21m 下載時間Images都需要時間，也可以自己實作Build Dockerfile，生成後可以直接透過Jupyter Notebook做操作。 查看Pod生成狀態123456789$ kubectl describe pod jupyter-adminEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 34s default-scheduler Successfully assigned jupyter-admin to minikube Normal SuccessfulMountVolume 34s kubelet, minikube MountVolume.SetUp succeeded for volume &quot;pvc-11a86a3d-a8cd-11e8-8ff4-080027920b17&quot; Normal SuccessfulMountVolume 34s kubelet, minikube MountVolume.SetUp succeeded for volume &quot;no-api-access-please&quot; Normal Pulling 33s kubelet, minikube pulling image &quot;gcr.io/kubeflow/tensorflow-notebook-cpu:latest 如果環境下載太慢，可以嘗試連接已經部署好的環境，使用JupyterHubhttp://140.128.18.98:31715/ Kubeflow Use TF-operator確認已經下載kubeflow-broadmission1git clone https://github.com/kairen/kubeflow-broadmission.git TFJob是一個Kubernetes 自定義資源(CRD)，可以在Kubernetes上輕鬆運行TensorFlow訓練工作 進入tf-operator資料夾，執行簡易的tfjob測試1$ kubectl create -f tf-job-cpu.yml 執行 yaml如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061apiVersion: kubeflow.org/v1alpha2kind: TFJobmetadata: labels: experiment: experiment10 name: tfjob namespace: kubeflowspec: tfReplicaSpecs: Ps: replicas: 1 template: metadata: creationTimestamp: null spec: containers: - args: - python - tf_cnn_benchmarks.py - --batch_size=32 - --model=resnet50 - --variable_update=parameter_server - --flush_stdout=true - --num_gpus=1 - --local_parameter_device=cpu - --device=cpu - --data_format=NHWC image: gcr.io/kubeflow/tf-benchmarks-cpu:v20171202-bdab599-dirty-284af3 name: tensorflow ports: - containerPort: 2222 name: tfjob-port resources: &#123;&#125; workingDir: /opt/tf-benchmarks/scripts/tf_cnn_benchmarks restartPolicy: OnFailure Worker: replicas: 1 template: metadata: creationTimestamp: null spec: containers: - args: - python - tf_cnn_benchmarks.py - --batch_size=32 - --model=resnet50 - --variable_update=parameter_server - --flush_stdout=true - --num_gpus=1 - --local_parameter_device=cpu - --device=cpu - --data_format=NHWC image: gcr.io/kubeflow/tf-benchmarks-cpu:v20171202-bdab599-dirty-284af3 name: tensorflow ports: - containerPort: 2222 name: tfjob-port resources: &#123;&#125; workingDir: /opt/tf-benchmarks/scripts/tf_cnn_benchmarks restartPolicy: OnFailur 透過TF-operator管理，我們可以透過調整replicas來增加分散式訓練的works數量 確認執行tfjob狀態123kubectl get tfjob NAME CREATED ATtfjob 5m 監控tfjob狀態12345678910111213141516$ kubectl get -o yaml tfjobs $JOBstatus: conditions: - lastTransitionTime: 2018-08-26T03:57:32Z lastUpdateTime: 2018-08-26T03:57:32Z message: TFJob tfjob is running. reason: TFJobRunning status: \"True\" type: Running startTime: 2018-08-26T04:11:33Z tfReplicaStatuses: PS: active: 1 Worker: active: 1 可以透過確認tfjob執行狀態Running 透過觀察tfjob生成tf-benchmarks 包含PS、worker 目前pod狀態1234567891011121314$ kubectl get podNAME READY STATUS RESTARTS AGEambassador-59cb5ccd89-mxdpz 2/2 Running 0 1hambassador-59cb5ccd89-nzcbt 2/2 Running 0 1hambassador-59cb5ccd89-rzrs5 2/2 Running 0 1hcentraldashboard-7d7744cccb-kh7r6 1/1 Running 0 1hjupyter-admin 1/1 Running 0 1hspartakus-volunteer-56d4cf6bbf-vf9nt 1/1 Running 0 1htf-hub-0 1/1 Running 0 1htf-job-dashboard-bfc9bc6bc-zfk64 1/1 Running 0 1htf-job-operator-v1alpha2-756cf9cb97-w2w9q 1/1 Running 0 1htfjob-ps-0 1/1 Running 0 23mtfjob-worker-0 1/1 Running 0 23m 觀察tfjob-worker-0狀態1234567891011121314151617181920$ kubectl logs -f tfjob-worker-0INFO|2018-08-26T03:57:34|/opt/launcher.py|27| TensorFlow: 1.5INFO|2018-08-26T03:57:34|/opt/launcher.py|27| Model: resnet50INFO|2018-08-26T03:57:34|/opt/launcher.py|27| Mode: trainingINFO|2018-08-26T03:57:34|/opt/launcher.py|27| SingleSess: FalseINFO|2018-08-26T03:57:34|/opt/launcher.py|27| Batch size: 32 globalINFO|2018-08-26T03:57:34|/opt/launcher.py|27| 32 per deviceINFO|2018-08-26T03:57:34|/opt/launcher.py|27| Devices: ['/job:worker/task:0/cpu:0']INFO|2018-08-26T03:57:34|/opt/launcher.py|27| Data format: NHWCINFO|2018-08-26T03:57:34|/opt/launcher.py|27| Optimizer: sgdINFO|2018-08-26T03:57:34|/opt/launcher.py|27| Variables: parameter_serverINFO|2018-08-26T03:57:34|/opt/launcher.py|27| Sync: TrueINFO|2018-08-26T03:57:34|/opt/launcher.py|27| ==========INFO|2018-08-26T03:57:34|/opt/launcher.py|27| Generating modelINFO|2018-08-26T03:57:41|/opt/launcher.py|27| 2018-08-26 03:57:41.378160: I tensorflow/core/distributed_runtime/master_session.cc:1008] Start master session 1d102ed86769e21e with config: intra_op_parallelism_threads: 1 gpu_options &#123; force_gpu_compatible: true &#125; allow_soft_placement: trueINFO|2018-08-26T03:57:44|/opt/launcher.py|27| Running warm upINFO|2018-08-26T04:10:31|/opt/launcher.py|27| Done warm upINFO|2018-08-26T04:10:31|/opt/launcher.py|27| Step Img/sec lossINFO|2018-08-26T04:11:52|/opt/launcher.py|27| 1 images/sec: 0.4 +/- 0.0 (jitter = 0.0) 10.224 如果要直接刪除tfjob1ks -n $&#123;NAMESPACE&#125; delete tfjobs &#123;JOB_NAME&#125; kubeflow MPI 連結這邊直接參考資料夾 yaml範例 檢查是否已安裝mpijobs自定義資源12345$ kubectl get crdNAME AGE...mpijobs.kubeflow.org 4d... 可以透過kosnnet添加1234cd $&#123;KSONNET_APP&#125;ks pkg install kubeflow/mpi-jobks generate mpi-operator mpi-operatorks apply $&#123;ENVIRONMENT&#125; -c mpi-operator 或是直接create crd.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142434445apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: mpijobs.kubeflow.orgspec: group: kubeflow.org version: v1alpha1 scope: Namespaced names: plural: mpijobs singular: mpijob kind: MPIJob shortNames: - mj - mpij validation: openAPIV3Schema: properties: spec: title: The MPIJob spec description: Either `gpus` or `replicas` should be specified, but not both oneOf: - properties: gpus: title: Total number of GPUs description: Valid values are 1, 2, 4, or any multiple of 8 oneOf: - type: integer enum: - 1 - 2 - 4 - type: integer multipleOf: 8 minimum: 8 required: - gpus - properties: replicas: title: Total number of replicas description: The GPU resource limit should be specified for each replica type: integer minimum: 1 required: - replicas Kubeflow Deploy PytorchKubeflow使用自定義資源定義（CRD）和Operator擴展了Kubernetes。每個自定義資源都是協助機器學習工作負載的部署。定義資源後，Operator將處理部署請求。 查看目前環境中的CRD資源：1234$ kubectl get crdNAME CREATED ATtfjobs.kubeflow.org 2018-08-26T02:56:54Z 在kubeflow 0.2.2，默認是沒有部署Pytorch Operator，需要額外下命令部署CRD和Operator。123cd kubeflow_ks_appks generate pytorch-operator pytorch-operatorks apply default -c pytorch-operator 重新查看kubectl get crd確認1234$ kubectl get crdNAME AGEpytorchjobs.kubeflow.org 6mtfjobs.kubeflow.org 8m Download pytorch-operator1git clone https://github.com/yylin1/kubeflow-broadmission.git 測試mnist訓練需要事先部署Docker Image12cd pytorch-operator/examples/dist-mnist/docker build -f Dockerfile -t kubeflow / pytorch-dist-mnist-test：1.0 ./ PyTorch 分散式訓練分佈式MNIST模型已打包到Container Image中。可以在Github上查看Python PyTorch代碼。 要部署培訓模型，PyTorchJob需要。這定義了要使用的容器映像以及用於分發培訓的副本數。 可以查看一個示例 cat examples/dist-mnist/pytorch_job_mnist.yaml執行部屬PyTorchJob開始訓練：1kubectl create -f examples/dist-mnist/pytorch_job_mnist.yaml 查看目前創建的Pod與指定的Work副本數量1kubectl get pods -l pytorch_job_name=dist-mnist-for-e2e-test 12345AME READY STATUS RESTARTS AGEdist-mnist-for-e2e-test-master-nl90-0-tcbly 0/1 ContainerCreating 0 5sdist-mnist-for-e2e-test-worker-nl90-1-wtidy 0/1 ContainerCreating 0 4sdist-mnist-for-e2e-test-worker-nl90-2-8t25x 0/1 ContainerCreating 0 3sdist-mnist-for-e2e-test-worker-nl90-3-t1i6z 0/1 ContainerCreating 0 3s 預設minist訓練為10個epoch約需要在Cluster執行5-10分鐘。可以透過查看日誌了解訓練進度。12PODNAME=$(kubectl get pods -l pytorch_job_name=dist-mnist-for-e2e-test,task_index=0 -o name)kubectl logs -f $&#123;PODNAME&#125; 1234567891011$ kubectl logs -f $&#123;PODNAME&#125;Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gzDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gzDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gzDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gzProcessing...Done!Rank 0 , epoch 0 : 1.2745472780232237... 監控PyTorch任務是否完成1kubectl get -o yaml pytorchjobs dist-mnist-for-e2e-test 可以透過輸出yaml來監控Job狀態。Job執行完成後state: Succeeded顯示成功。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465apiVersion: v1items:- apiVersion: kubeflow.org/v1alpha1 kind: PyTorchJob metadata: clusterName: \"\" creationTimestamp: 2018-06-22T08:16:14Z generation: 1 name: dist-mnist-for-e2e-test namespace: default resourceVersion: \"3276193\" selfLink: /apis/kubeflow.org/v1alpha1/namespaces/default/pytorchjobs/dist-mnist-for-e2e-test uid: 87772d3b-75f4-11e8-bdd9-42010aa00072 spec: RuntimeId: kmma pytorchImage: pytorch/pytorch:v0.2 replicaSpecs: - masterPort: 23456 replicaType: MASTER replicas: 1 template: metadata: creationTimestamp: null spec: containers: - image: gcr.io/kubeflow-ci/pytorch-dist-mnist_test:1.0 imagePullPolicy: IfNotPresent name: pytorch resources: &#123;&#125; restartPolicy: OnFailure - masterPort: 23456 replicaType: WORKER replicas: 3 template: metadata: creationTimestamp: null spec: containers: - image: gcr.io/kubeflow-ci/pytorch-dist-mnist_test:1.0 imagePullPolicy: IfNotPresent name: pytorch resources: &#123;&#125; restartPolicy: OnFailure terminationPolicy: master: replicaName: MASTER replicaRank: 0 status: phase: Done reason: \"\" replicaStatuses: - ReplicasStates: Succeeded: 1 replica_type: MASTER state: Succeeded - ReplicasStates: Running: 1 Succeeded: 2 replica_type: WORKER state: Running state: Succeededkind: Listmetadata: resourceVersion: \"\" selfLink: \"\" 若想從 Kubernetes 叢集刪除 Kubeflow 相關元件的話，可執行下列指令達成：1$ ks delete default -c kubeflow-core 補充kubeflow 0.2 Components TensorFlow Training Hyperparameter Tuning (Katib) Seldon Serving Istio Integration (for TF Serving) .. kubeflow","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yylin1.github.io/categories/kubernetes/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yylin1.github.io/tags/kubernetes/"},{"name":"kubeflow","slug":"kubeflow","permalink":"http://yylin1.github.io/tags/kubeflow/"},{"name":"GPU","slug":"GPU","permalink":"http://yylin1.github.io/tags/GPU/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-09-15T05:39:24.352Z","updated":"2018-09-15T05:39:24.352Z","comments":true,"path":"2018/09/15/hello-world/","link":"","permalink":"http://yylin1.github.io/2018/09/15/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}